{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288QGptWy2Ye"
      },
      "outputs": [],
      "source": [
        "# Task_1 , Dataset A\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import missingno as msno"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading all datasets\n",
        "folder = '/content/drive/MyDrive/Project/Challenge2023/datasetA_train'\n",
        "print(os.listdir(folder))\n",
        "files_to_merge = [i for i in os.listdir(folder) if 'A' in i]\n",
        "# reading one of them for making sure\n",
        "df_sample = pd.read_csv(os.path.join(folder, files_to_merge[0]))\n",
        "df_sample.head()"
      ],
      "metadata": {
        "id": "1hy5ztpp4wtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = pd.read_csv(os.path.join(folder, files_to_merge[1]))\n",
        "df_sample.head()"
      ],
      "metadata": {
        "id": "GkWO4t1Xdvs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering only patient_id as key for merging\n",
        "df_original_ID = pd.read_csv(os.path.join(folder, files_to_merge[0]))\n",
        "for i in range(len(files_to_merge[1:])):\n",
        "    df = pd.read_csv(os.path.join(folder, files_to_merge[i+1]))\n",
        "    df_original_ID  = pd.merge(df_original_ID, df, on=['patient_id'], how = 'outer')\n",
        "\n",
        "print(\"The size of final dataset is:\")\n",
        "print(df_original_ID.shape)"
      ],
      "metadata": {
        "id": "ehyOZns6MCZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centre_cols = [j for j in df_original_ID.columns if 'centre' in j]\n",
        "df_original_ID['center'] = df_original_ID[centre_cols].apply(lambda x: ', '.join(x.dropna().astype(str)),axis=1)\n",
        "\n",
        "def remove_duplicate_strings(sample):\n",
        "  list_strings = sample.split(', ')\n",
        "  unique_strings = list(set(list_strings))\n",
        "  unique_strings.sort()\n",
        "  return ', '.join(unique_strings)\n",
        "\n",
        "df_original_ID['center'] = df_original_ID['center'].apply(remove_duplicate_strings)\n",
        "cols_to_drop = [i for i in centre_cols if '_' in i]\n",
        "df_original_ID = df_original_ID.drop(columns=cols_to_drop)\n",
        "\n",
        "df_original_ID = df_original_ID.sort_values(by='patient_id', ascending=True)\n",
        "df_original_ID.reset_index(drop=True, inplace=True)\n",
        "df_original_ID.head()"
      ],
      "metadata": {
        "id": "ctCxU4HvQpcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of patients with considering only patient_id as key\n",
        "print(len(np.unique(df_original_ID[\"patient_id\"])))\n",
        "print(df_original_ID.isnull().sum())\n",
        "msno.bar(df_original_ID)"
      ],
      "metadata": {
        "id": "wH5BTXNcPf6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_original_ID.to_csv(\"Merged_data_ID.csv\", index = False)"
      ],
      "metadata": {
        "id": "ObFPJojqGAyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming that the time features privided in datasets are the same for all and considering time and patient_id as keys\n",
        "df_original_ID_Time = pd.read_csv(os.path.join(folder, files_to_merge[0]))\n",
        "time_col = [j for j in df_original_ID_Time.columns if 'time' in j]\n",
        "df_original_ID_Time.rename(columns={time_col[0]: \"time\"}, inplace = True)\n",
        "for i in range(len(files_to_merge[1:])):\n",
        "    df = pd.read_csv(os.path.join(folder, files_to_merge[i+1]))\n",
        "    time_col = [j for j in df.columns if 'time' in j]\n",
        "    df.rename(columns={time_col[0]: \"time\"}, inplace = True)\n",
        "    df_original_ID_Time  = pd.merge(df_original_ID_Time, df, on=['patient_id',\"time\"], how = 'outer')\n",
        "\n",
        "print(\"The size of final dataset is:\")\n",
        "print(df_original_ID_Time.shape)"
      ],
      "metadata": {
        "id": "w1aL7eULxtPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicated features\n",
        "centre_cols = [j for j in df_original_ID_Time.columns if 'centre' in j]\n",
        "df_original_ID_Time['center'] = df_original_ID_Time[centre_cols].apply(lambda x: ', '.join(x.dropna().astype(str)),axis=1)\n",
        "\n",
        "def remove_duplicate_strings(sample):\n",
        "  list_strings = sample.split(', ')\n",
        "  unique_strings = list(set(list_strings))\n",
        "  unique_strings.sort()\n",
        "  return ', '.join(unique_strings)\n",
        "\n",
        "df_original_ID_Time['center'] = df_original_ID_Time['center'].apply(remove_duplicate_strings)\n",
        "cols_to_drop = [i for i in centre_cols if '_' in i]\n",
        "df_original_ID_Time = df_original_ID_Time.drop(columns=cols_to_drop)\n",
        "\n",
        "df_original_ID_Time = df_original_ID_Time.sort_values(by='patient_id', ascending=True)\n",
        "df_original_ID_Time.reset_index(drop=True, inplace=True)\n",
        "df_original_ID_Time.head()"
      ],
      "metadata": {
        "id": "XSbCrZDrRrkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of patient with considering time and patient_id as keys\n",
        "print(len(np.unique(df_original_ID_Time[\"patient_id\"])))\n",
        "print(df_original_ID_Time.isnull().sum())\n",
        "msno.bar(df_original_ID_Time)"
      ],
      "metadata": {
        "id": "9No439cxO_a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the final data\n",
        "df_original_ID_Time.to_csv(\"Merged_data_Time_ID.csv\", index = False)"
      ],
      "metadata": {
        "id": "obdF0vrKEjVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X82QP_XXF5wF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}